{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook will translate the output of xCP from a hdf5 file to .csv and .xlsx (Excel) files for easier analysis. Input and output paths for this script are located in cell 1 and should be changed for each user. By default, the script will write the columns ApplicationDates, ApplicationDayMonth, FeatureID, ApplicationRate(g/ha), AppliedPPP, AppliedArea(ha), and TechnologyDriftReductions. Applied mass(g) can also be calculated by modifying cells 5 and 10.\n",
    "\n",
    "Version 3.0 - 2/3/2026 Added Excel export capability with auto-sized columns\n",
    "\n",
    "Version 2.0 - 11/15/2024 Added feature LULC to output\n",
    "\n",
    "Version 1.0 - 5/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input and output file paths - change these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Generate timestamp for output files\n",
    "timestamp = datetime.datetime.now().strftime('%y-%m-%d-%H-%M-%S')\n",
    "\n",
    "# Input hdf file location\n",
    "xcrop_arrdat_path = r'C:\\LocalWork\\xCropProtectionDemo\\run\\test-SingleField_100x100_dev2\\mcs\\X3MMTWPX35V272P8RP\\store\\arr.dat'\n",
    "# Output CSV file location and name\n",
    "output_csv_path = rf'C:\\LocalWork\\xCropProtectionDemo\\run\\test-SingleField_100x100_dev2\\test-SingleField_100x100_dev2_xCP_output_{timestamp}.csv'\n",
    "# Output Excel file location and name\n",
    "output_excel_path = rf'C:\\LocalWork\\xCropProtectionDemo\\run\\test-SingleField_100x100_dev2\\test-SingleField_100x100_dev2_xCP_output_{timestamp}.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import datetime\n",
    "import pandas\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all subgroups are h5py datasets\n",
    "def checkInstance(datasets):\n",
    "    for dataset in datasets:\n",
    "        if not isinstance(dataset, h5py.Dataset):\n",
    "            print(dataset, \"is not a h5py dataset.\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "try:\n",
    "    arr_file = h5py.File(xcrop_arrdat_path, 'r')\n",
    "except FileNotFoundError:\n",
    "    print(\"The file\", xcrop_arrdat_path, \"could not be accessed\")\n",
    "\n",
    "dataset = arr_file['xCropProtection']\n",
    "landscape_dataset = arr_file['LandscapeScenario']\n",
    "\n",
    "# Get data for subgroups\n",
    "application_dates_subgroup = dataset['ApplicationDates']\n",
    "application_rates_subgroup = dataset['ApplicationRates']\n",
    "application_areas = dataset['AppliedAreas']\n",
    "applied_features = dataset['AppliedFields']\n",
    "application_PPP = dataset['AppliedPPP']\n",
    "xcrop_file_path = dataset['xCropProtectionFilePath']\n",
    "drift_reduction = dataset['TechnologyDriftReductions']\n",
    "\n",
    "feature_ids = landscape_dataset['FeatureIds']\n",
    "feature_type_ids = landscape_dataset['FeatureTypeIds']\n",
    "epsg = landscape_dataset['EPSG']\n",
    "\n",
    "# Check that subgroups are h5py datasets\n",
    "if not checkInstance([application_dates_subgroup, application_rates_subgroup, application_PPP, xcrop_file_path, drift_reduction]):\n",
    "    print(\"Error retrieving subgroup data.\")\n",
    "    arr_file.close()\n",
    "    quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_dates_data = application_dates_subgroup[:]\n",
    "application_rates_data = application_rates_subgroup[:]\n",
    "applied_features_data = applied_features[:]\n",
    "application_PPP_data = application_PPP[:]\n",
    "application_areas_data = application_areas[:]\n",
    "drift_reduction_data = drift_reduction[:]\n",
    "epsg_data = epsg[()]\n",
    "feature_ids_data = feature_ids[:]\n",
    "feature_type_ids_data = feature_type_ids[:]\n",
    "\n",
    "# Create dictionary of feature ids and their lulc type\n",
    "feature_id_lulc_dict = {}\n",
    "for index, fid in enumerate(feature_ids_data):\n",
    "    feature_id_lulc_dict[fid] = feature_type_ids_data[index]\n",
    "\n",
    "feature_lulc = [feature_id_lulc_dict.get(x) for x in applied_features_data]\n",
    "\n",
    "application_dates = [datetime.date.fromordinal(x) for x in application_dates_data]\n",
    "application_dates_day_month = [datetime.date.fromordinal(x).strftime('%d-%B') for x in application_dates_data]\n",
    "\n",
    "# Convert application area arrays to bytes for geometry creation\n",
    "app_areas_bytes = [x.tobytes() for x in application_areas] \n",
    "\n",
    "field_geometries = geopandas.GeoDataFrame(\n",
    "    geometry=geopandas.GeoSeries.from_wkb(app_areas_bytes),\n",
    "    crs=\"EPSG:\" + str(epsg_data)\n",
    ").to_crs(crs=\"EPSG:4326\")\n",
    "field_geometries[\"field_idx\"] = field_geometries.reset_index().index\n",
    "\n",
    "# Project geometry and calculate area\n",
    "geom_project = field_geometries.to_crs(crs=\"EPSG:\" + str(epsg_data))\n",
    "geom_project_area_m = geom_project.area\n",
    "geom_project_area_ha = geom_project_area_m / 10000\n",
    "\n",
    "# Convert from bytes to string\n",
    "decode_PPP = [x.decode() for x in application_PPP_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_id_type_dict = {}\n",
    "for i, feature_id in enumerate(feature_ids_data):\n",
    "    feature_id_type_dict[feature_id] = feature_type_ids_data[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: C:\\LocalWork\\xCropProtectionDemo\\run\\test-SingleField_100x100_dev2\\test-SingleField_100x100_dev2_xCP_output_26-02-05-12-26-02.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "# Comment out any line which is not desired in the output\n",
    "dfs.append(pandas.DataFrame(application_dates, columns=[\"ApplicationDates\"]))\n",
    "dfs.append(pandas.DataFrame(application_dates_day_month, columns=[\"ApplicationDayMonth\"]))\n",
    "dfs.append(pandas.DataFrame(applied_features_data, columns=[\"FeatureID\"]))\n",
    "dfs.append(pandas.DataFrame([feature_id_type_dict.get(x) for x in applied_features_data], columns=[\"FeatureLULC\"]))\n",
    "dfs.append(pandas.DataFrame(application_rates_data, columns=[\"ApplicationRates(g/ha)\"]))\n",
    "dfs.append(pandas.DataFrame(decode_PPP, columns=[\"AppliedPPP\"]))\n",
    "dfs.append(pandas.DataFrame(geom_project_area_ha, columns=[\"AppliedArea(ha)\"]))\n",
    "#dfs.append(pandas.DataFrame(application_rates_data * geom_project_area_ha, columns=[\"AppliedMass(g)\"]))\n",
    "dfs.append(pandas.DataFrame(drift_reduction_data, columns=[\"TechnologyDriftReductions\"]))\n",
    "merged_df = pandas.concat(dfs, axis=1)        \n",
    "merged_df.to_csv(output_csv_path, index=False)   \n",
    "print(f\"CSV file saved to: {output_csv_path}\")\n",
    "arr_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write data to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved to: C:\\LocalWork\\xCropProtectionDemo\\run\\test-SingleField_100x100_dev2\\test-SingleField_100x100_dev2_xCP_output_26-02-05-12-26-02.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Reopen the file to get the data for Excel export\n",
    "arr_file = h5py.File(xcrop_arrdat_path, 'r')\n",
    "dataset = arr_file['xCropProtection']\n",
    "landscape_dataset = arr_file['LandscapeScenario']\n",
    "\n",
    "# Retrieve the same data\n",
    "application_dates_data = dataset['ApplicationDates'][:]\n",
    "application_rates_data = dataset['ApplicationRates'][:]\n",
    "applied_features_data = dataset['AppliedFields'][:]\n",
    "application_PPP_data = dataset['AppliedPPP'][:]\n",
    "application_areas_data = dataset['AppliedAreas'][:]\n",
    "drift_reduction_data = dataset['TechnologyDriftReductions'][:]\n",
    "epsg_data = landscape_dataset['EPSG'][()]\n",
    "feature_ids_data = landscape_dataset['FeatureIds'][:]\n",
    "feature_type_ids_data = landscape_dataset['FeatureTypeIds'][:]\n",
    "\n",
    "# Recreate the processed data\n",
    "feature_id_lulc_dict = {}\n",
    "for index, fid in enumerate(feature_ids_data):\n",
    "    feature_id_lulc_dict[fid] = feature_type_ids_data[index]\n",
    "\n",
    "application_dates = [datetime.date.fromordinal(x) for x in application_dates_data]\n",
    "application_dates_day_month = [datetime.date.fromordinal(x).strftime('%d-%B') for x in application_dates_data]\n",
    "\n",
    "app_areas_bytes = [x.tobytes() for x in application_areas_data] \n",
    "field_geometries = geopandas.GeoDataFrame(\n",
    "    geometry=geopandas.GeoSeries.from_wkb(app_areas_bytes),\n",
    "    crs=\"EPSG:\" + str(epsg_data)\n",
    ").to_crs(crs=\"EPSG:4326\")\n",
    "field_geometries[\"field_idx\"] = field_geometries.reset_index().index\n",
    "\n",
    "geom_project = field_geometries.to_crs(crs=\"EPSG:\" + str(epsg_data))\n",
    "geom_project_area_m = geom_project.area\n",
    "geom_project_area_ha = geom_project_area_m / 10000\n",
    "\n",
    "decode_PPP = [x.decode() for x in application_PPP_data]\n",
    "\n",
    "# Create DataFrame for Excel export\n",
    "excel_dfs = []\n",
    "excel_dfs.append(pandas.DataFrame(application_dates, columns=[\"ApplicationDates\"]))\n",
    "excel_dfs.append(pandas.DataFrame(application_dates_day_month, columns=[\"ApplicationDayMonth\"]))\n",
    "excel_dfs.append(pandas.DataFrame(applied_features_data, columns=[\"FeatureID\"]))\n",
    "excel_dfs.append(pandas.DataFrame([feature_id_lulc_dict.get(x) for x in applied_features_data], columns=[\"FeatureLULC\"]))\n",
    "excel_dfs.append(pandas.DataFrame(application_rates_data, columns=[\"ApplicationRates(g/ha)\"]))\n",
    "excel_dfs.append(pandas.DataFrame(decode_PPP, columns=[\"AppliedPPP\"]))\n",
    "excel_dfs.append(pandas.DataFrame(geom_project_area_ha, columns=[\"AppliedArea(ha)\"]))\n",
    "#excel_dfs.append(pandas.DataFrame(application_rates_data * geom_project_area_ha, columns=[\"AppliedMass(g)\"]))\n",
    "excel_dfs.append(pandas.DataFrame(drift_reduction_data, columns=[\"TechnologyDriftReductions\"]))\n",
    "\n",
    "excel_df = pandas.concat(excel_dfs, axis=1)\n",
    "\n",
    "# Write to Excel with formatting\n",
    "with pandas.ExcelWriter(output_excel_path, engine='openpyxl') as writer:\n",
    "    excel_df.to_excel(writer, sheet_name='xCP_Output', index=False)\n",
    "    \n",
    "    # Get the workbook and worksheet\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['xCP_Output']\n",
    "    \n",
    "    # Auto-adjust column widths\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(str(cell.value))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = min(max_length + 2, 50)  # Cap at 50 to avoid extremely wide columns\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "print(f\"Excel file saved to: {output_excel_path}\")\n",
    "arr_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
